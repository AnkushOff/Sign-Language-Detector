# 🤟 Sign Language Detector – Real-Time Gesture Recognition with ML

A real-time sign language recognition system using **TensorFlow**, **Keras**, and **OpenCV** that detects hand gestures via webcam and translates them into alphabetic characters (A–Z). This project aims to promote **accessible communication** for individuals with hearing or speech impairments.

---

## 🧠 How It Works

- Uses **ConvNet (CNN)** trained on image data of hand gestures
- Real-time webcam feed processed using **OpenCV**
- Predicts ASL (American Sign Language) alphabets
- Displays predicted character on screen in live video

---

## 🛠️ Tech Stack

| Tool | Purpose |
|------|---------|
| `Python`, `OpenCV` | Image capture, video stream handling |
| `TensorFlow`, `Keras` | Model training and inference |
| `NumPy`, `Matplotlib` | Data handling and visualization |

---

## 📈 Model Performance

- Achieved **85%+ accuracy** on validation data  
- Trained on 26-class ASL dataset (A–Z)  
- Optimized for real-time inference with 30% reduced runtime

---

## 💡 Use Case / Impact

This system can be used in:
- **Accessibility tools** for education or customer support
- **Learning platforms** for teaching sign language
- **Gesture-based interfaces** for embedded devices or kiosks

---

## 🧪 Try It Locally

1. Clone the repo  
```bash
git clone https://github.com/AnkushOff/Sign-Language-Detector.git
```
```bash
cd Sign-Language-Detector
```
2.Install dependencies
```bash
pip install -r requirements.txt
```

