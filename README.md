# ğŸ¤Ÿ Sign Language Detector â€“ Real-Time Gesture Recognition with ML

A real-time sign language recognition system using **TensorFlow**, **Keras**, and **OpenCV** that detects hand gestures via webcam and translates them into alphabetic characters (Aâ€“Z). This project aims to promote **accessible communication** for individuals with hearing or speech impairments.

---

## ğŸ§  How It Works

- Uses **ConvNet (CNN)** trained on image data of hand gestures
- Real-time webcam feed processed using **OpenCV**
- Predicts ASL (American Sign Language) alphabets
- Displays predicted character on screen in live video

---

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|------|---------|
| `Python`, `OpenCV` | Image capture, video stream handling |
| `TensorFlow`, `Keras` | Model training and inference |
| `NumPy`, `Matplotlib` | Data handling and visualization |

---

## ğŸ“ˆ Model Performance

- Achieved **85%+ accuracy** on validation data  
- Trained on 26-class ASL dataset (Aâ€“Z)  
- Optimized for real-time inference with 30% reduced runtime

---

## ğŸ’¡ Use Case / Impact

This system can be used in:
- **Accessibility tools** for education or customer support
- **Learning platforms** for teaching sign language
- **Gesture-based interfaces** for embedded devices or kiosks

---

## ğŸ§ª Try It Locally

1. Clone the repo  
```bash
git clone https://github.com/AnkushOff/Sign-Language-Detector.git
```
```bash
cd Sign-Language-Detector
```
2.Install dependencies
```bash
pip install -r requirements.txt
```

